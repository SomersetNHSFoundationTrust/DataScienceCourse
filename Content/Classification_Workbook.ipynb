{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a3c8955",
   "metadata": {},
   "source": "# Classification"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f125dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need to install fetch_ucirepo using the below commented line of code\n",
    "\n",
    "# pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d73f4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Imports required for notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad28ef1a",
   "metadata": {},
   "source": [
    "Useful resources for classification concepts:\n",
    "* Essential Math for Data Science: Thomas Nield (Chapter 6)\n",
    "* StatsQuest Guide to Machine Learning: Josh Starmer\n",
    "* ISLP: https://www.statlearning.com/ (Chapter 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545c4f59",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42c832",
   "metadata": {},
   "source": [
    "### Motivation for Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3518745d",
   "metadata": {},
   "source": [
    "Suppose we are collecting some information from patients as they enter A&E. A health metric is collected as a patient enters A&E and is thought this metric will provide a good indication of whether or not the patient will be admitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a fake dataset\n",
    "data = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=2,\n",
    "    n_informative=2,\n",
    "    n_redundant=0,\n",
    "    n_repeated=0,\n",
    "    n_classes=2,\n",
    "    random_state=42,\n",
    ")\n",
    "X = data[0][:, 1]  # Patient metric\n",
    "y = data[1]  # Whether or not the patient is admitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc729384",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data = pd.DataFrame(X, columns=[\"patient_metric\"])\n",
    "classification_data[\"patient_admitted\"] = y\n",
    "\n",
    "X = classification_data[[\"patient_metric\"]].values\n",
    "y = classification_data[\"patient_admitted\"].values\n",
    "classification_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56f5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship in Plotly using a scatter chart\n",
    "\n",
    "los_fig = px.scatter(classification_data, x=\"patient_metric\", y=\"patient_admitted\")\n",
    "los_fig.update_layout(\n",
    "    yaxis_title=\"Patient admitted (1) or not (0)\",\n",
    "    title=\"Evaluating the relationship between a metric and patient admissions\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bec0b0d",
   "metadata": {},
   "source": [
    "We can see the probability of the patient being admitted increases as the metric increases, above around 1 it's likely they will be admitted and below -1, it's likely they won't. What if the metric is 0? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b861b5",
   "metadata": {},
   "source": [
    "We could try to fit a linear regression model to this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf6bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_fig = px.scatter(classification_data, x=\"patient_metric\", y=\"patient_admitted\", trendline=\"ols\")\n",
    "lr_fig.update_layout(\n",
    "    yaxis_title=\"Patient admitted (1) or not (0)\",\n",
    "    title=\"Using linear regression for binary outcomes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59214b7b",
   "metadata": {},
   "source": [
    "There are some problems with this approach:\n",
    "1. Its not possible to derive meaningful estimates for probabilities.\n",
    "2. Linear regression is heavily influenced by outliers.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33255c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_df = pd.DataFrame(columns = ['patient_metric', 'patient_admitted'])\n",
    "outliers_df['patient_metric'] = [50]\n",
    "outliers_df['patient_admitted'] = [1]\n",
    "\n",
    "lr_fig = px.scatter(pd.concat([classification_data, outliers_df]), x=\"patient_metric\", y=\"patient_admitted\", trendline=\"ols\")\n",
    "lr_fig.update_layout(\n",
    "    yaxis_title=\"Patient admitted (1) or not (0)\",\n",
    "    title=\"Using linear regression for binary outcomes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c88da",
   "metadata": {},
   "source": [
    "Ideally, we would have a function that takes our metric as input and returns a value between 0 and 1 that represents the probability of being admitted or not (linear regression is not bound between 0 and 1)... this is what Logistic Regression can do!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d0e988",
   "metadata": {},
   "source": [
    "### Fitting a logistic regression model using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b180eb8d",
   "metadata": {},
   "source": [
    "The Logistic regression (see more info on ISLP page 139)\n",
    "\n",
    "$p(X) = \\frac{e^{\\beta_0 + \\beta_1X}}{1 + e^{\\beta_0 + \\beta_1X}}$, where $p$ represents probability, for a given $X$ input and $\\beta_0$, $\\beta_1$ are the coefficients, where $0\\leqslant p(x) \\leqslant 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908f96e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data into training & testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=random_seed, test_size=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just as with linear regression, we save an instance of LogisticRegression()\n",
    "logistic_regression = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a753b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our logistic function to training data\n",
    "logistic_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5440792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient term\n",
    "beta_1 = logistic_regression.coef_[0][0]\n",
    "print(beta_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163fec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intercept term\n",
    "beta_0 = logistic_regression.intercept_[0]\n",
    "print(beta_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc60e6a",
   "metadata": {},
   "source": [
    "We have a coefficient and an intercept, just like linear regression.. ***coincidence?*** Perhaps not..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b338b",
   "metadata": {},
   "source": [
    "### Logistic Function background theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974b9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the linear function from the regression section\n",
    "def linear_function(b_0, b_1, x_array):\n",
    "    \"\"\"\n",
    "    Linear function.\n",
    "    Inputs:\n",
    "        b_0 (float): Coefficient of linear function\n",
    "        b_1 (float): Intercept (bias) term\n",
    "        x_array (numpy.array): Input x values\n",
    "    returns\n",
    "        numpy.array. Outputs from a linear function.\n",
    "    \"\"\"\n",
    "\n",
    "    return b_0 * x_array + b_1\n",
    "\n",
    "\n",
    "# Create a python function for logistic regression\n",
    "def logistic_function(linear_function):\n",
    "    \"\"\"\n",
    "    Sigmoid function.\n",
    "    Inputs:\n",
    "        b_0 (float): Coefficient of linear function\n",
    "        b_1 (float): Intercept (bias) term\n",
    "        x_array (numpy.array): Input x values\n",
    "    returns\n",
    "        numpy.array. Outputs from a linear function.\n",
    "    \"\"\"\n",
    "\n",
    "    return np.exp((linear_function)) / (1 + np.exp((linear_function)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fa3c1d",
   "metadata": {},
   "source": [
    "Lets take the coefficient and intercept returned from the `logistic_regression`model above and plot the line this gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa6eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_output = linear_function(\n",
    "    logistic_regression.coef_[0][0],\n",
    "    logistic_regression.intercept_[0],\n",
    "    np.linspace(-5, 4, 1000),\n",
    ")\n",
    "# Print first values\n",
    "linear_output[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fig = px.line(\n",
    "    x=np.linspace(-5, 4, 1000),\n",
    "    y=linear_output,\n",
    "    title=\"Plotting line using logistic regression outputs\",\n",
    ")\n",
    "log_fig.update_layout(yaxis_title=\"Log odds\")\n",
    "log_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ef2c9",
   "metadata": {},
   "source": [
    "We wont go into too much detail on this, but this line describes the relationship between an input (i.e., patient health metric) and the log-odds.\n",
    "\n",
    "To get back to probability from log-odds, we apply the sigmoid function to the linear output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2098db",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_line_using_sigmoid = logistic_function(linear_output)\n",
    "# Print first 10 transformed values\n",
    "transform_line_using_sigmoid[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d3c0b3",
   "metadata": {},
   "source": [
    "Plot the transformed line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d519cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fig = px.line(\n",
    "    x=np.linspace(-5, 4, 1000),\n",
    "    y=linear_output,\n",
    "    title=\"Plotting line using logistic regression outputs\",\n",
    ")\n",
    "\n",
    "log_fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.linspace(-5, 5, 1000),\n",
    "        y=transform_line_using_sigmoid,\n",
    "        name=\"Transformed linear model\",\n",
    "    )\n",
    ")\n",
    "log_fig.update_yaxes(range=[-0.5, 1.5])\n",
    "log_fig.update_layout(yaxis_title=\"Probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4c93ee",
   "metadata": {},
   "source": [
    "The sigmoid function has collapsed the linear regression function to fall within the bounds 0 to 1. Lets overlay this sigmoid function to our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea319062",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = px.scatter(\n",
    "    classification_data, x=\"patient_metric\", y=\"patient_admitted\"\n",
    ")\n",
    "logistic_model.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.linspace(-5, 4, 1000),\n",
    "        y=logistic_function(linear_output),\n",
    "        name=\"Fitted Logistic model\",\n",
    "    )\n",
    ")\n",
    "logistic_model.update_layout(title=\"Modelling our data using a Sigmoid function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40209fc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Logistic regression is backed by linear function!</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6246a9",
   "metadata": {},
   "source": [
    "If we need to make a prediction on whether or not a patient will be admitted, we input a value into the logistic function and observe if the output is closer to 0 or 1 (typically, a threhsold of 0.5 is used for binary classification). This probability can be extracted using the `.predict_proba()` method on the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f477d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of being 0 (first value) or 1 (second value) when a patient has a metric\n",
    "# values of -1.2\n",
    "logistic_regression.predict_proba([[-1.2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d1a3e3",
   "metadata": {},
   "source": [
    "Note, the order to probabilities correspondes to the order in the `.classes_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f468ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e5f38",
   "metadata": {},
   "source": [
    "You can also make a binary prediction using the `.predict()` method on the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df82ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression.predict([[-1.2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eca460",
   "metadata": {},
   "source": [
    "We can assess model accuracy, as with linear regression, by using the `.score()` method on the trained model. Lets observe the score for the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3748888",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eccfad",
   "metadata": {},
   "source": [
    "Here, accuracy referrs to the proportion of ***correct predictions***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e56ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where model prediction and observed values are the same\n",
    "correct_predictions = np.sum(\n",
    "    y_test == logistic_regression.predict(X_test)\n",
    ")\n",
    "print(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of test data\n",
    "test_len = len(y_test)\n",
    "print(test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = correct_predictions / test_len\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d198a163",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Logistic regression key points</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf793a12",
   "metadata": {},
   "source": [
    "1. The logistic regression model allows us to model and make predictions when our output is categorical (specifically, a binary outcome).\n",
    "2. We have a method to represent the probabaility of a binary outcome given a set of input values. This could represent our level of confidence in a prediction. This can then be converted to a binary prediction.\n",
    "3. We can extend the use of a single input variable (in a similar manner to multiple linear regression) to inlude multiple input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e361e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Logistic regression warnings:</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b20535e",
   "metadata": {},
   "source": [
    "1. Although not all assumptions are required for logistic regression as with linear regression, we need to be careful of multicollinearity and independence in error terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccca6a3",
   "metadata": {},
   "source": [
    "***Task 1 (15-20 mins)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf0462",
   "metadata": {},
   "source": [
    "In this task, we will use a dataset with the target variable indicating whether or not a patient has heart diseae.There are 13 independent variables, however, lets use just `'max-heart-rate'` as our single feature.\n",
    "\n",
    "*Target variable*\n",
    "* 1 = Absence of heart disease\n",
    "* 2 = Prescence of heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset\n",
    "statlog_heart = fetch_ucirepo(id=145)\n",
    "\n",
    "# Extract data\n",
    "features = statlog_heart.data.features\n",
    "target = statlog_heart.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e08efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in dataframe\n",
    "task_1_data = pd.DataFrame(features)[[\"max-heart-rate\"]]\n",
    "task_1_data[\"heart-disease\"] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5eda4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate into features and target\n",
    "X = task_1_data[[\"max-heart-rate\"]].values\n",
    "y = task_1_data[\"heart-disease\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5dc7c2",
   "metadata": {},
   "source": [
    "1. Visualise the relationship between max heart rate and whether or not someone has heart disease using plotly express scatter (or another visualisation library of your choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ad8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132ea89",
   "metadata": {},
   "source": [
    "2. Seperate the data into training and testing (use 30% of the data for testing and make sure to shuffle the data). Ensure the `random_state` is set to 42 (so everyone gets the same answer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c28e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8471aeab",
   "metadata": {},
   "source": [
    "3. Fit a `LogisticRegression()` model to the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88544ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d356171",
   "metadata": {},
   "source": [
    "4. Compute the model accuracy on the unseen testing data using the `score()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd5ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed2f9fa",
   "metadata": {},
   "source": [
    "5. Predict the probability of someone having heart disease with `'max-heart-rate'` of 178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09158b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32206797",
   "metadata": {},
   "source": [
    "### Evaluating classification outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1447bea",
   "metadata": {},
   "source": [
    "Based on the first task, the four possible outcomes from the classification prediction are:\n",
    "\n",
    "* Predicts heart disease, and patient actually has heart disease ***(true positives)***.\n",
    "* Predicts *no* heart disease, and patient does * ***not*** * have heart disease ***(true negatives)***. \n",
    "* Predicts heart disease, and patient does * ***not*** * have heart disease ***(false positives)***. \n",
    "* Predicts *no* heart disease, and patient actually has heart disease ***(false negatives)***. \n",
    "\n",
    "This information can be summarised using a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92007d",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7dc3b1",
   "metadata": {},
   "source": [
    "Lets make a new fake dataset, looking at whether or not a patient gets admitted based on some calculated metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=2,\n",
    "    n_informative=2,\n",
    "    n_redundant=0,\n",
    "    n_repeated=0,\n",
    "    n_classes=2,\n",
    "    random_state=42,\n",
    ")\n",
    "X = data[0][:, 1]  # Patient metric\n",
    "y = data[1]  # Whether or not the patient is admitted\n",
    "\n",
    "# save fake data\n",
    "classification_data = pd.DataFrame(X, columns=[\"Metric\"])\n",
    "classification_data[\"patient_admitted\"] = y\n",
    "\n",
    "X = classification_data[[\"Metric\"]]\n",
    "y = classification_data['patient_admitted']\n",
    "\n",
    "# train logistic regression model\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cacdb7",
   "metadata": {},
   "source": [
    "Visualise data and fitted logistic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fig = px.scatter(\n",
    "    classification_data,\n",
    "    x=\"Metric\",\n",
    "    y=\"patient_admitted\",\n",
    "    title=\"Trained logistic model\",\n",
    ")\n",
    "\n",
    "# Generate many predictions to plot the logistic function\n",
    "proba = logistic_regression.predict_proba(np.linspace(-5, 4, 100).reshape(-1, 1))[:, 1]\n",
    "\n",
    "# Add trace of logistic function using predictions\n",
    "log_fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.linspace(-5, 4, 100), y=proba, mode=\"lines\", name=\"Logistic function\"\n",
    "    )\n",
    ")\n",
    "log_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62adbd4a",
   "metadata": {},
   "source": [
    "Using `metrics.confusion_matrix` from `sklearn` allows us to use built in funcionality to calculate the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95926856",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(\n",
    "    y_true=y, y_pred=logistic_regression.predict(X)\n",
    ")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe96049",
   "metadata": {},
   "source": [
    "Note, this is the order of the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c790cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = metrics.confusion_matrix(y, logistic_regression.predict(X)).ravel()\n",
    "print(f'True negatives = {tn}')\n",
    "print(f'False postives = {fp}')\n",
    "print(f'False negatives = {fn}')\n",
    "print(f'True postives = {tp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2c348",
   "metadata": {},
   "source": [
    "Use Plotly express `imshow` to display confusion matrix as heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b14749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(\n",
    "    confusion_matrix,\n",
    "    text_auto=True,\n",
    "    labels=dict(x=\"Predicted outcome\", y=\"Actual outcome\"),\n",
    "    x=[\"0\", \"1\"],\n",
    "    y=[\"0\", \"1\"],\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Predicted outcome\",\n",
    "    yaxis_title=\"Actual outcome\",\n",
    "    title=\"Confusion matrix\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a051ee",
   "metadata": {},
   "source": [
    "Depending on the scenario, is this number of missed positives (i.e., false negatives) acceptable? \n",
    "\n",
    "Would you rather wrongly predict a patient that ***should*** be admitted, or wrongly predict a patient that ***shouldn't*** be admitted?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09df81ac",
   "metadata": {},
   "source": [
    "#### Receiver Operator Characteristics (ROC) curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820c5e4b",
   "metadata": {},
   "source": [
    "In Logistic Regession, we have values we can use to represent probabilties. By default (using `.predict()`) Logistic Regression will use a 0.5 threshold i.e., values below 0.5 will go to class 0 (not admitted) and values above will go to class 1 (admitted).\n",
    "\n",
    "Is there any easy way to compare the numbers of true positives and false positives when we change this 0.5 threhold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities of assigning to class\n",
    "y_score = logistic_regression.predict_proba(X)[:, 1]\n",
    "\n",
    "# Print first 10 prediction probabilities\n",
    "print(y_score[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0b5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve points\n",
    "false_positive_rate, true_positive_rate, threshold = metrics.roc_curve(\n",
    "    y_true=y, y_score=y_score, pos_label=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_fig = go.Figure()\n",
    "roc_fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=false_positive_rate,\n",
    "        y=true_positive_rate,\n",
    "        mode=\"lines\",\n",
    "        text=[\"Threshold: \" + str(round(x, 3)) for x in threshold],\n",
    "        hoverinfo=\"text\",\n",
    "        line=dict(width=3),\n",
    "        name=\"ROC curve\",\n",
    "    )\n",
    ")\n",
    "roc_fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, 1],\n",
    "        y=[0, 1],\n",
    "        name=\"Random guess\",\n",
    "        line_shape=\"linear\",\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"green\", width=4, dash=\"dash\"),\n",
    "    )\n",
    ")\n",
    "roc_fig.update_layout(\n",
    "    xaxis_title=\"False positive rate\",\n",
    "    yaxis_title=\"True positive rate\",\n",
    "    title=\"Reciever Operator Curve (ROC)\",\n",
    ")\n",
    "\n",
    "roc_fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0],\n",
    "        y=[1],\n",
    "        mode=\"markers+text\",\n",
    "        name=\"Perfect classifier\",\n",
    "        text=[\"The perfect classifier\"],\n",
    "        textposition=\"bottom right\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "roc_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b11ec56",
   "metadata": {},
   "source": [
    "Note, False positive rate = $\\frac{FP}{FP + TN}$ & True positive rate = $\\frac{TP}{TP + FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd1f4e",
   "metadata": {},
   "source": [
    "### Class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceba574",
   "metadata": {},
   "source": [
    "Suppose we have been asked to create a prediction model to predict whether someone has a rare medical condition. We use diagnostic imaging as features to predict whether not the virus is present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    # the usual parameters\n",
    "    n_samples=500,\n",
    "    n_features=5,\n",
    "    n_informative=3,\n",
    "    n_classes=2,\n",
    "    random_state=42,\n",
    "    # Set label 0 for  98% and 1 for rest 3% of observations\n",
    "    weights=[0.99],\n",
    ")\n",
    "classification_data = pd.DataFrame(X)\n",
    "classification_data[\"patient_admitted\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c3c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238ffd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace3d671",
   "metadata": {},
   "source": [
    "Wow! this looks like this is a pretty good model! ... or does it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d25bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y, logistic_regression.predict(X))\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67540351",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(\n",
    "    confusion_matrix,\n",
    "    text_auto=True,\n",
    "    labels=dict(x=\"Predicted outcome\", y=\"Actual outcome\"),\n",
    "    x=[\"0\", \"1\"],\n",
    "    y=[\"0\", \"1\"],\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Predicted outcome\",\n",
    "    yaxis_title=\"Actual outcome\",\n",
    "    title=\"Confusion matrix of predictions\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e57a2e",
   "metadata": {},
   "source": [
    "What is the problem with using this accuracy metric for this data?\n",
    "\n",
    "To make a good model, we need to adress the imbalance in the data (typically through resampling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8ff3a0",
   "metadata": {},
   "source": [
    "***Task 2 (10-15 mins)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c74c334",
   "metadata": {},
   "source": [
    "1. Using the logistic model built in task 1, derive and plot, the confusion matrix for the test data. Make use of `metrics.confusion_matrix` for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99fa4f5",
   "metadata": {},
   "source": [
    "2. How many negative predictions were incorrect (false negatives)? How many missed positives do you think are acceptable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0489e43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7400f52",
   "metadata": {},
   "source": [
    "### Using machine learning models in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2b31b8",
   "metadata": {},
   "source": [
    "- It's important to ensure the training data is free from bias (it's representative of the population you are studying).\n",
    "- The code should be fully transparent (includes documentation and is freely available).\n",
    "- Models arent perfect, and therefore should be used in conjunction with expert opinion (human & AI collaboration).\n",
    "- Some simple models have been introduced, but more advanceded models are capable of improved prediction (ensemble techniques) which can be discussed during full training days."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
