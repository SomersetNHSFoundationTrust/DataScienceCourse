{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a3c8955",
   "metadata": {},
   "source": [
    "# Classification workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports required for notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "random_seed=42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545c4f59",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42c832",
   "metadata": {},
   "source": [
    "### Motivation for Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3518745d",
   "metadata": {},
   "source": [
    "Suppose we are collecting some information from patients as they enter A&E. A health metric is collected as a patient enters A&E and is thought this metric will provide a good indication of whether or not the patient will be admitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a fake dataset\n",
    "data = make_classification(n_samples=1000,\n",
    "                           n_features=2,\n",
    "                           n_informative=2,\n",
    "                           n_redundant=0, \n",
    "                           n_repeated=0,\n",
    "                           n_classes=2,\n",
    "                           random_state=42)\n",
    "X = data[0][:, 1]  # Patient metric\n",
    "y = data[1]  # Whether or not the patient is admitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc729384",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data = pd.DataFrame(X, columns = ['patient_metric'])\n",
    "classification_data['patient_admitted'] = y\n",
    "classification_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56f5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship in Plotly using a scatter chart\n",
    "\n",
    "los_fig = px.scatter(classification_data, x = 'patient_metric', y = 'patient_admitted')\n",
    "los_fig.update_layout(yaxis_title='Patient admitted (1) or not (0)',\n",
    "                      title = 'Evaluating the relationship between a metric and patient admissions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bec0b0d",
   "metadata": {},
   "source": [
    "We can see the probability of the patient being admitted increases as the metric increases, above around 1 it's likely they will be admitted and below -1, it's likely they won't. What if the metric is 0? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c88da",
   "metadata": {},
   "source": [
    "Ideally, we would have a function that takes our metric as input and returns a value between 0 and 1 that represents the probability of being admitted or not... this is what Logistic Regression can do!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d0e988",
   "metadata": {},
   "source": [
    "### Fitting a logistic regression model using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908f96e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data into training & testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=random_seed, \n",
    "                                                    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just as with linear regression, we save an instance of LogisticRegression()\n",
    "logistic_regression = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a753b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our logistic function to training data\n",
    "logistic_regression.fit(X_train.reshape(-1, 1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5440792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient term\n",
    "beta_1 = logistic_regression.coef_[0][0]\n",
    "print(beta_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163fec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intercept term\n",
    "beta_0 = logistic_regression.intercept_[0]\n",
    "print(beta_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc60e6a",
   "metadata": {},
   "source": [
    "We have a coefficient and an intercept, just like linear regression.. ***coincidence?*** Perhaps not..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b338b",
   "metadata": {},
   "source": [
    "### Logistic Function background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974b9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the linear function from the regression section\n",
    "def linear_function(b_0, b_1, x_array):\n",
    "    \n",
    "    '''\n",
    "    Inputs:\n",
    "        b_0 (float): Coefficient of linear function\n",
    "        b_1 (float): Intercept (bias) term\n",
    "        x_array (numpy.array): Input x values \n",
    "    returns\n",
    "        numpy.array. Outputs from a linear function.\n",
    "    '''\n",
    "    \n",
    "    return b_0*x_array+b_1\n",
    "\n",
    "# Create a python function for logistic regression\n",
    "def logistic_function(linear_function):\n",
    "    \n",
    "    '''\n",
    "    Inputs:\n",
    "        b_0 (float): Coefficient of linear function\n",
    "        b_1 (float): Intercept (bias) term\n",
    "        x_array (numpy.array): Input x values \n",
    "    returns\n",
    "        numpy.array. Outputs from a linear function.\n",
    "    '''\n",
    "    \n",
    "    return 1/(1 + np.exp(-(linear_function)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fa3c1d",
   "metadata": {},
   "source": [
    "Lets take the coefficient and intercept returned from the `logistic_regression`model above and plot the regression line this gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa6eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_output = linear_function(logistic_regression.coef_[0][0],\n",
    "                                logistic_regression.intercept_[0],\n",
    "                                np.linspace(-5, 4, 1000))\n",
    "# Print first values\n",
    "linear_output[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fig = px.line(x = np.linspace(-5, 5, 1000),\n",
    "                  y = linear_output, \n",
    "                  title = 'Plotting line using logistic regression outputs')\n",
    "log_fig.update_layout(yaxis_title = 'Log odds')\n",
    "log_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ef2c9",
   "metadata": {},
   "source": [
    "We wont go into too much detail on this, but this is actually describes a line that predicts something called the log-odds. \n",
    "\n",
    "To get back to probability from log-odds, we apply the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2098db",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_line_using_sigmoid = logistic_function(linear_output)\n",
    "# Print first 10 transformed values\n",
    "transform_line_using_sigmoid[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d3c0b3",
   "metadata": {},
   "source": [
    "Plot the transformed line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d519cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fig.add_trace(go.Scatter(x = np.linspace(-5, 5, 1000),\n",
    "                             y = transform_line_using_sigmoid,\n",
    "                             name = 'Transformed linear model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4c93ee",
   "metadata": {},
   "source": [
    "The sigmoid function has collapsed the linear regression function to fall within the bounds 0 to 1. Lets overlay this sigmoid function to our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea319062",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = px.scatter(classification_data, x = 'patient_metric', y = 'patient_admitted')\n",
    "logistic_model.add_trace(go.Scatter(x = np.linspace(-5, 4, 1000),\n",
    "                                    y = logistic_function(linear_output),\n",
    "                                    name = 'Fitted Logistic model'))\n",
    "logistic_model.update_layout(title = 'Modelling our data using a Sigmoid function')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40209fc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Logistic regression is backed by linear function!</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6246a9",
   "metadata": {},
   "source": [
    "If we need to make a prediction on whether or not a patient will be admitted, we input a value into the logistic function and observe if the output is closer to 0 or 1 (typically, a threhsold of 0.5 is used for binary classification). This probability can be extracted using the `.predict_proba()` method on the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f477d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of being 0 (first value) or 1 (second value) when a patient has a metric\n",
    "# values of -1.2\n",
    "logistic_regression.predict_proba([[-1.2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e5f38",
   "metadata": {},
   "source": [
    "Make a binary prediction using the `.predict()` method on the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df82ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression.predict([[-1.2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eca460",
   "metadata": {},
   "source": [
    "We can assess model accuracy, as with linear regression, by using the `.score()` method on the trained model. Lets observe the score for the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3748888",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression.score(X_test.reshape(-1, 1), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eccfad",
   "metadata": {},
   "source": [
    "Here, accuracy referrs to the number of ***correct predictions*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e56ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where model prediction and observed values are the same\n",
    "correct_predictions = np.sum(y_test == logistic_regression.predict(X_test.reshape(-1, 1)))\n",
    "print(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of test data\n",
    "test_len = len(y_test)\n",
    "print(test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = correct_predictions/test_len\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d198a163",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Logistic regression key points</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf793a12",
   "metadata": {},
   "source": [
    "1. The logistic regression model allows us to model and make predictions when our output is categorical (specifically, a binary outcome).\n",
    "2. We have a method to represent the probabaility of a binary outcome given a set of input values. This could represent our level of confidence in a prediction. This can then be converted to a binary prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccca6a3",
   "metadata": {},
   "source": [
    "***Task 1 (15-20 mins)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf0462",
   "metadata": {},
   "source": [
    "In this task, we will use a dataset with the target variable indicating whether or not a patient has heart diseae.There are 13 independent variables, however, lets use just `'max-heart-rate'` as our single feature.\n",
    "\n",
    "*Target variable*\n",
    "* 1 = Absence of heart disease\n",
    "* 2 = Prescence of heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "statlog_heart = fetch_ucirepo(id=145) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = statlog_heart.data.features \n",
    "y = statlog_heart.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5eda4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1_data = pd.DataFrame(X)[['max-heart-rate']]\n",
    "task_1_data['heart-disease'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5dc7c2",
   "metadata": {},
   "source": [
    "1. Visualise the relationship between max heart rate and whether or not someone has heart disease using plotly express scatter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ad8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132ea89",
   "metadata": {},
   "source": [
    "2. Seperate the data into training and testing (use 20% of the data for testing and make sure to shuffle the data). Ensure the `random_state` is set to 42 (so everyone gets the same answer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c28e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8471aeab",
   "metadata": {},
   "source": [
    "3. Fit a `LogisticRegression()` model to the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88544ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d356171",
   "metadata": {},
   "source": [
    "4. Compute the model accuracy on the unseen testing data using the `score()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd5ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed2f9fa",
   "metadata": {},
   "source": [
    "5. Predict the probability of someone having heart disease with `'max-heart-rate'` of 178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09158b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32206797",
   "metadata": {},
   "source": [
    "### Evaluating classification outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1447bea",
   "metadata": {},
   "source": [
    "The four possible outcomes from a classification prediction are:\n",
    "\n",
    "* Predicts heart disease, and patient actually has heart disease ***(true positives)***.\n",
    "* Predicts *no* heart disease, and patient does * ***not*** * have heart disease ***(true negatives)***. \n",
    "* Predicts heart disease, and patient does * ***not*** * have heart disease ***(false positives)***. \n",
    "* Predicts *no* heart disease, and patient actually has heart disease ***(false negatives)***. \n",
    "\n",
    "This information can be summarised using a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92007d",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7dc3b1",
   "metadata": {},
   "source": [
    "Lets make a new fake dataset, looking at whether or not a patient gets admitted based on some calculated metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_classification(n_samples=1000,\n",
    "                           n_features=2,\n",
    "                           n_informative=2,\n",
    "                           n_redundant=0, \n",
    "                           n_repeated=0,\n",
    "                           n_classes=2,\n",
    "                           random_state=42)\n",
    "X = data[0][:, 1]  # Patient metric\n",
    "y = data[1]  # Whether or not the patient is admitted\n",
    "\n",
    "# save fake data\n",
    "classification_data = pd.DataFrame(X, columns = ['Metric'])\n",
    "classification_data['patient_admitted'] = y\n",
    "\n",
    "# train logistic regression model\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X.reshape(-1, 1), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cacdb7",
   "metadata": {},
   "source": [
    "Visualise data and fitted logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fig = px.scatter(classification_data, \n",
    "                     x = 'Metric', \n",
    "                     y = 'patient_admitted', \n",
    "                     title = 'Trained logistic model')\n",
    "\n",
    "# Generate many predictions to plot the logistic function\n",
    "proba = logistic_regression.predict_proba(np.linspace(-5, 4, 100).reshape(-1, 1))[:, 1]\n",
    "\n",
    "# Add trace of logistic function using predictions\n",
    "log_fig.add_trace(go.Scatter(x = np.linspace(-5, 4, 100), \n",
    "                             y = proba, \n",
    "                             mode = 'lines', \n",
    "                             name = 'Logistic function'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62adbd4a",
   "metadata": {},
   "source": [
    "Using `metrics.confusion_matrix` from `sklearn` allows us to use built in funcionality to calculate the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95926856",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_true = y,\n",
    "                                            y_pred = logistic_regression.predict(X.reshape(-1, 1))\n",
    "                                           )\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2c348",
   "metadata": {},
   "source": [
    "Use Plotly express `imshow` to display confusion matrix as heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b14749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(confusion_matrix, \n",
    "                text_auto=True, \n",
    "                labels=dict(x=\"Predicted outcome\", \n",
    "                            y=\"Actual outcome\"),\n",
    "                x=['0', '1'],\n",
    "                y=['0', '1']\n",
    "               )\n",
    "\n",
    "fig.update_layout(xaxis_title='Predicted outcome', \n",
    "                  yaxis_title='Actual outcome',\n",
    "                  title = 'Confusion matrix')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a051ee",
   "metadata": {},
   "source": [
    "Depending on the scenario, is this number of missed positives (i.e., false negatives) acceptable? \n",
    "\n",
    "Would you rather wrongly predict a patient that ***should*** be admitted, or wrongly predict a patient that ***shouldn't*** be admitted?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09df81ac",
   "metadata": {},
   "source": [
    "#### Receiver Operator Characteristics (ROC) curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820c5e4b",
   "metadata": {},
   "source": [
    "In Logistic Regession, we have values we can use to represent probabilties. By default (using `.predict()`) Logistic Regression will use a 0.5 threshold i.e., values below 0.5 will go to class 0 (not admitted) and values above will go to class B (admitted).\n",
    "\n",
    "Is there any easy way to compare the numbers of true positives and false positives when we change this 0.5 threhold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities of assigning to class \n",
    "y_score = logistic_regression.predict_proba(X.reshape(-1, 1))[:,1]\n",
    "\n",
    "# Print first 10 prediction probabilities\n",
    "print(y_score[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0b5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve points\n",
    "false_positive_rate, true_positive_rate, threshold = metrics.roc_curve(y_true = y,\n",
    "                                                                       y_score = y_score, \n",
    "                                                                       pos_label = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_fig = go.Figure()\n",
    "roc_fig.add_trace(go.Scatter(x = false_positive_rate,\n",
    "                             y = true_positive_rate,\n",
    "                             mode='lines',\n",
    "                             text = ['Threshold: ' + str(round(x, 3)) for x in threshold],\n",
    "                             hoverinfo = 'text',\n",
    "                             line = dict(width=3),\n",
    "                             name='ROC curve'\n",
    "))\n",
    "roc_fig.add_trace(go.Scatter(x=[0, 1],\n",
    "                             y=[0, 1],\n",
    "                             name=\"Random guess\",\n",
    "                             line_shape='linear',\n",
    "                             mode='lines',\n",
    "                             line=dict(color='green', width=4, dash='dash'))\n",
    ")\n",
    "roc_fig.update_layout(xaxis_title='False positive rate', \n",
    "                      yaxis_title='True positive rate', \n",
    "                      title = 'Reciever Operator Curve (ROC)')\n",
    "\n",
    "roc_fig.add_trace(go.Scatter(\n",
    "    x=[0],\n",
    "    y=[1],\n",
    "    mode=\"markers+text\",\n",
    "    name=\"Perfect classifier\",\n",
    "    text=[\"The perfect classifier\"],\n",
    "    textposition=\"bottom right\"\n",
    "))\n",
    "\n",
    "\n",
    "roc_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd1f4e",
   "metadata": {},
   "source": [
    "### Class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceba574",
   "metadata": {},
   "source": [
    "Suppose we have been asked to create a prediction model to predict whether someone has a rare medical condition. We use diagnostic imaging as features to predict whether not the virus is present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    # the usual parameters\n",
    "    n_samples=500, \n",
    "    n_features=5, \n",
    "    n_informative=3, \n",
    "    n_classes=2, \n",
    "    random_state=42,\n",
    "    # Set label 0 for  98% and 1 for rest 3% of observations\n",
    "    weights=[0.99], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c3c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data = pd.DataFrame(X)\n",
    "classification_data['patient_admitted'] = y\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "logistic_regression.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238ffd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace3d671",
   "metadata": {},
   "source": [
    "Wow! this looks like this is a pretty good model! ... or does it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d25bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y, logistic_regression.predict(X))\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67540351",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(confusion_matrix, \n",
    "                text_auto=True, \n",
    "                labels=dict(x=\"Predicted outcome\", y=\"Actual outcome\"),\n",
    "                x=['0', '1'],\n",
    "                y=['0', '1']\n",
    "               )\n",
    "\n",
    "fig.update_layout(xaxis_title='Predicted outcome', \n",
    "                  yaxis_title='Actual outcome', \n",
    "                 title = 'Confusion matrix of predictions')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e57a2e",
   "metadata": {},
   "source": [
    "What is the problem with using this accuray metric for this data?\n",
    "\n",
    "To make a good model, we need to adress the imbalance in the data (typically through resampling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8ff3a0",
   "metadata": {},
   "source": [
    "***Task 2 (15-20 mins)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c74c334",
   "metadata": {},
   "source": [
    "1. Using the model built in task 1, derive and plot, the confusion matrix for the test data. Make use of `metrics.confusion_matrix` for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28224b7f",
   "metadata": {},
   "source": [
    "2. It is important that no more than 5% of heart disease patients are missed by the prediction model. Using the test dataset, can you estimate what threshold you would need to set in the logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e489df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8135978c",
   "metadata": {},
   "source": [
    "***Hint:*** Obtain the probabilities using the `.predict_proba()` method. You can then either use trial and error, evaluate the ROC curve or use a recursive loop to ensure the FNR < 0.05. Note, FNR = 1 - TPR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
